# -*- coding: utf-8 -*-
"""aeroDeit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xdBCisuQG_kKkS2K1kqHpDlI9qh5AYyr

#Summary
In this project, a machine learning model is developed to classify aero-engine defects. The process involves using a pre-trained DeiT model for feature extraction, UMAP for dimensionality reduction, and an ensemble model combining Random Forest and XGBoost classifiers. SHAP (SHapley Additive exPlanations) is used to interpret the model's predictions.

#Key steps include:

Data Preparation: Downloading the dataset from Kaggle, extracting it, and preparing the paths for images and labels.
Feature Extraction: Using the DeiT model, pre-trained on ImageNet, to extract embeddings (features) from the images.
Dimensionality Reduction: Applying UMAP to reduce the high-dimensional embeddings to a 2D space for visualization.
Model Training:
Splitting the data into training and validation sets.
Training a Random Forest classifier with hyperparameter tuning.
Training an XGBoost model.
Creating an ensemble model that combines both classifiers.
Model Evaluation: Evaluating the ensemble model using precision, recall, and f1-score metrics and visualizing the confusion matrix.
Model Interpretation: Using SHAP to explain the model's predictions and visualize the importance of features.
#Goal
The goal of this project is to build a robust classification model for aero-engine defects and understand the underlying factors influencing the model's decisions.
"""

# Install necessary packages
!pip install --quiet torch torchvision transformers img2vec_pytorch umap-learn plotly scikit-learn shap
print('pip install torch, torchvision, transformers, img2vec_pytorch, umap-learn, plotly, scikit-learn, and shap complete.')

import os
import zipfile
import torch
from transformers import DeiTFeatureExtractor, DeiTModel
from torchvision import transforms
import base64
import pandas as pd
from glob import glob
from torch.autograd import Variable
from io import BytesIO
from os.path import basename
from PIL import Image
import plotly.express as px
import umap
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
import xgboost as xgb
import shap
import numpy as np

# Securely handle Kaggle API key
os.makedirs('/root/.kaggle', exist_ok=True)
with open('/root/.kaggle/kaggle.json', 'w') as f:
    f.write('{"username":"samimohammadi","key":"4ab63d79c9e2574c91adf402d3ed7aec"}')
os.chmod('/root/.kaggle/kaggle.json', 0o600)

# Download and unzip dataset
!kaggle datasets download -d wolfmedal/aero-engine-defect-new
with zipfile.ZipFile('aero-engine-defect-new.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/aero-engine-defect-new')

# Verify the correct paths
base_dir = '/content/aero-engine-defect-new/Aero-engine_defect-detect_new'
train_img_dir = os.path.join(base_dir, 'images/train')
train_labels_dir = os.path.join(base_dir, 'labels/train')

# Define the model and feature extractor
feature_extractor = DeiTFeatureExtractor.from_pretrained('facebook/deit-base-distilled-patch16-224')
deit_model = DeiTModel.from_pretrained('facebook/deit-base-distilled-patch16-224')
deit_model.eval()

# Define image transformation
transform = transforms.Compose([
    transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

def embed(model, feature_extractor, filename: str):
    try:
        with Image.open(fp=filename, mode='r') as image:
            inputs = feature_extractor(images=image, return_tensors="pt")
            with torch.no_grad():
                outputs = model(**inputs)
            return outputs.last_hidden_state[:, 0, :].numpy().reshape(768,)
    except Exception as e:
        print(f"Error processing file {filename}: {e}")
        return None

def flatten(arg):
    return [x for xs in arg for x in xs]

def png(filename: str) -> str:
    with Image.open(fp=filename, mode='r') as image:
        buffer = BytesIO()
        image.thumbnail(size=THUMBNAIL_SIZE)
        image.save(fp=buffer, format='png')
        return base64.b64encode(buffer.getvalue()).decode()

root = os.path.join(base_dir, 'labels')
dfs = []
for subfolder in ['val', 'train']:
    for input_file in glob(pathname=os.path.join(root, subfolder, '*.txt')):
        current_df = pd.read_csv(filepath_or_buffer=input_file, sep=' ', names=['label', 'w0', 'w1', 'w2', 'w3'])
        current_df['tag'] = [subfolder] * len(current_df)
        current_df['name'] = basename(input_file)
        dfs.append(current_df)
labels_df = pd.concat(objs=dfs, axis=0)
labels_df['image_name'] = labels_df['name'].apply(lambda x: x.replace('.txt', '.jpg'))
labels_df.head()
labels_df['class'] = labels_df['label'].map({0: 'scratch', 1: 'dot', 2: 'crease', 3: 'damage'})

# Create embeddings for all images
image_paths = glob(os.path.join(train_img_dir, '*.jpg'))
embeddings = []
for img_path in image_paths:
    vec = embed(deit_model, feature_extractor, img_path)
    if vec is not None:
        embeddings.append(vec)

# Convert embeddings to a DataFrame for further processing
embeddings_df = pd.DataFrame(embeddings)
embeddings_df['image_name'] = [basename(p) for p in image_paths]

# Join embeddings with labels
all_df = embeddings_df.merge(right=labels_df, on='image_name', how='inner')

# Perform UMAP dimensionality reduction
reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, metric='correlation')
embedding_2d = reducer.fit_transform(embeddings_df.iloc[:, :-1])

# Create a DataFrame for visualization
vis_df = pd.DataFrame(embedding_2d, columns=['UMAP1', 'UMAP2'])
vis_df['label'] = all_df['label']

# Plot the 2D UMAP projection
fig = px.scatter(vis_df, x='UMAP1', y='UMAP2', color='label', title='UMAP projection of image embeddings')
fig.show()

# Convert column names to strings
all_df.columns = all_df.columns.astype(str)

# Ensure the labels are in the correct format
all_df['label'] = all_df['label'].astype(int)

# Exclude the 'image_name' column from the features
X = all_df.drop(columns=['image_name', 'label', 'name', 'tag', 'class'])
y = all_df['label']

# Split the data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Initialize and train the Random Forest model with hyperparameter tuning
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}
grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42), param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)
grid_search.fit(X_train, y_train)
best_rf = grid_search.best_estimator_

# Train an additional XGBoost model
xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
xgb_model.fit(X_train, y_train)

# Create an ensemble model
ensemble_model = VotingClassifier(estimators=[('rf', best_rf), ('xgb', xgb_model)], voting='soft')
ensemble_model.fit(X_train, y_train)

# Evaluate the ensemble model
y_pred_ensemble = ensemble_model.predict(X_val)
print(classification_report(y_val, y_pred_ensemble, target_names=['scratch', 'dot', 'crease', 'damage']))

# Print confusion matrix
cm = confusion_matrix(y_val, y_pred_ensemble)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['scratch', 'dot', 'crease', 'damage'], yticklabels=['scratch', 'dot', 'crease', 'damage'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Extract and print average metrics
report = classification_report(y_val, y_pred_ensemble, target_names=['scratch', 'dot', 'crease', 'damage'], output_dict=True)
avg_metrics = {
    'precision': report['weighted avg']['precision'],
    'recall': report['weighted avg']['recall'],
    'f1-score': report['weighted avg']['f1-score']
}

print(f"\nAverage metrics:\n{avg_metrics}")

# Plot average metrics
metrics_names = ['precision', 'recall', 'f1-score']
avg_metrics_values = [avg_metrics[metric] for metric in metrics_names]

plt.figure(figsize=(8, 5))
plt.bar(metrics_names, avg_metrics_values, color=['blue', 'green', 'red'])
plt.xlabel('Metrics')
plt.ylabel('Average Value')
plt.title('Average Metrics')
plt.ylim(0, 1)
plt.show()

# SHAP for interpretability using the best Random Forest model
explainer = shap.Explainer(best_rf, X_train)
shap_values = explainer(X_val)

# Debugging: Print shapes of SHAP values and feature names
print(f"SHAP values shape: {shap_values.shape}")
print(f"Feature names length: {len(X.columns)}")

# Convert feature names to a list
feature_names = X.columns.tolist()

# Select SHAP values for class 0
shap_values_class_0 = shap_values[..., 0]

# Ensure shap_values have the correct structure
shap_values_explanation = shap.Explanation(values=shap_values_class_0.values, base_values=shap_values_class_0.base_values, data=X_val, feature_names=feature_names)

# Plot SHAP summary
shap.summary_plot(shap_values_explanation, features=X_val.values, feature_names=feature_names)

# Visualization function
def visualize_top_activations(embedding_dim_index, embeddings, image_paths, top_n=5):
    # Get the top N images with the highest values in the specified embedding dimension
    top_indices = np.argsort(embeddings[:, embedding_dim_index])[-top_n:]

    plt.figure(figsize=(15, 5))
    for i, index in enumerate(top_indices):
        img_path = image_paths[index]
        img = Image.open(img_path)
        plt.subplot(1, top_n, i + 1)
        plt.imshow(img)
        plt.title(f'Value: {embeddings[index, embedding_dim_index]:.2f}')
        plt.axis('off')

    plt.suptitle(f'Top {top_n} images for embedding dimension {embedding_dim_index}')
    plt.show()

# Example usage for w2 (assuming w2 is at index 2 in the embeddings array)
visualize_top_activations(2, np.array(embeddings), image_paths)

# Example usage for w3 (assuming w3 is at index 3 in the embeddings array)
visualize_top_activations(3, np.array(embeddings), image_paths)

# Assume embeddings is a numpy array with the image embeddings
embeddings = np.array(embeddings)

# Calculate the min and max values for each dimension
min_values = np.min(embeddings, axis=0)
max_values = np.max(embeddings, axis=0)

# Print the ranges for each dimension
for i in range(embeddings.shape[1]):
    print(f"Dimension {i}: min={min_values[i]}, max={max_values[i]}")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image
import os
from glob import glob

# Define the function to visualize images with bounding boxes
def visualize_top_images_with_bboxes(feature_name, shap_values, image_paths, labels_df, n=3):
    # Get the indices of the images with the highest SHAP values for the given feature
    shap_values_for_feature = shap_values[:, labels_df.columns.get_loc(feature_name)]
    top_indices = np.argsort(-np.abs(shap_values_for_feature))[:n]

    for idx in top_indices:
        image_path = image_paths[idx]
        shap_value = shap_values_for_feature[idx]

        # Read the image
        try:
            image = Image.open(image_path)
        except FileNotFoundError:
            print(f"File not found: {image_path}")
            continue

        # Get bounding box coordinates from labels_df
        image_name = os.path.basename(image_path)
        original_image_name = image_name.split('_')[0] + '.jpg'
        label_row = labels_df[labels_df['image_name'] == original_image_name]
        if not label_row.empty:
            w0, w1, w2, w3 = label_row[['w0', 'w1', 'w2', 'w3']].values[0]
            print(f"Bounding box for {image_name}: w0={w0}, w1={w1}, w2={w2}, w3={w3}")
        else:
            print(f"No label data found for image {image_path}")
            continue

        # Plot the image
        fig, ax = plt.subplots(1)
        ax.imshow(image)

        # Create a Rectangle patch
        rect = patches.Rectangle((w0, w1), w2-w0, w3-w1, linewidth=2, edgecolor='r', facecolor='none')

        # Add the patch to the Axes
        ax.add_patch(rect)

        plt.title(f'SHAP value for {feature_name}: {shap_value:.4f}')
        plt.show()

# Securely handle Kaggle API key
os.makedirs('/root/.kaggle', exist_ok=True)
with open('/root/.kaggle/kaggle.json', 'w') as f:
    f.write('{"username":"samimohammadi","key":"4ab63d79c9e2574c91adf402d3ed7aec"}')
os.chmod('/root/.kaggle/kaggle.json', 0o600)

# Download and unzip dataset
!kaggle datasets download -d wolfmedal/aero-engine-defect-new
with zipfile.ZipFile('aero-engine-defect-new.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/aero-engine-defect-new')

# Verify the correct paths
base_dir = '/content/aero-engine-defect-new/Aero-engine_defect-detect_new'
train_img_dir = os.path.join(base_dir, 'images/train')
train_labels_dir = os.path.join(base_dir, 'labels/train')

# Assuming image_paths is a list of paths to images in train_img_dir
image_paths = [os.path.join(train_img_dir, img) for img in os.listdir(train_img_dir) if img.endswith('.jpg')]

# Define the labels dataframe
root = os.path.join(base_dir, 'labels')
dfs = []
for subfolder in ['val', 'train']:
    for input_file in glob(pathname=os.path.join(root, subfolder, '*.txt')):
        current_df = pd.read_csv(filepath_or_buffer=input_file, sep=' ', names=['label', 'w0', 'w1', 'w2', 'w3'])
        current_df['tag'] = [subfolder] * len(current_df)
        current_df['name'] = basename(input_file)
        dfs.append(current_df)
labels_df = pd.concat(objs=dfs, axis=0)
labels_df['image_name'] = labels_df['name'].apply(lambda x: x.replace('.txt', '.jpg'))
labels_df['class'] = labels_df['label'].map({0: 'scratch', 1: 'dot', 2: 'crease', 3: 'damage'})

# Assume the `shap_values` array is already defined
# Example dummy `shap_values` array for illustration; replace with actual shap_values
shap_values = np.random.rand(len(image_paths), len(labels_df.columns))

# Visualize the top images with bounding boxes for w2 and w3
visualize_top_images_with_bboxes('w2', shap_values, image_paths, labels_df)
visualize_top_images_with_bboxes('w3', shap_values, image_paths, labels_df)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image
import os
from glob import glob

# Define the function to visualize images with bounding boxes
def visualize_top_images_with_bboxes(feature_name, shap_values, image_paths, labels_df, n=3):
    # Get the indices of the images with the highest SHAP values for the given feature
    shap_values_for_feature = shap_values[:, labels_df.columns.get_loc(feature_name)]
    top_indices = np.argsort(-np.abs(shap_values_for_feature))[:n]

    for idx in top_indices:
        image_path = image_paths[idx]
        shap_value = shap_values_for_feature[idx]

        # Read the image
        try:
            image = Image.open(image_path)
        except FileNotFoundError:
            print(f"File not found: {image_path}")
            continue

        # Get bounding box coordinates from labels_df
        image_name = os.path.basename(image_path)
        original_image_name = image_name.split('_')[0] + '.jpg'
        label_row = labels_df[labels_df['image_name'] == original_image_name]
        if not label_row.empty:
            w0, w1, w2, w3 = label_row[['w0', 'w1', 'w2', 'w3']].values[0]
            print(f"Bounding box for {image_name}: w0={w0}, w1={w1}, w2={w2}, w3={w3}")
        else:
            print(f"No label data found for image {image_path}")
            continue

        # Plot the image
        fig, ax = plt.subplots(1)
        ax.imshow(image)

        # Create a Rectangle patch
        rect = patches.Rectangle((w0, w1), w2-w0, w3-w1, linewidth=2, edgecolor='r', facecolor='none')

        # Add the patch to the Axes
        ax.add_patch(rect)

        plt.title(f'SHAP value for {feature_name}: {shap_value:.4f}')
        plt.show()

# Securely handle Kaggle API key
os.makedirs('/root/.kaggle', exist_ok=True)
with open('/root/.kaggle/kaggle.json', 'w') as f:
    f.write('{"username":"samimohammadi","key":"4ab63d79c9e2574c91adf402d3ed7aec"}')
os.chmod('/root/.kaggle/kaggle.json', 0o600)

# Download and unzip dataset
!kaggle datasets download -d wolfmedal/aero-engine-defect-new
with zipfile.ZipFile('aero-engine-defect-new.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/aero-engine-defect-new')

# Verify the correct paths
base_dir = '/content/aero-engine-defect-new/Aero-engine_defect-detect_new'
train_img_dir = os.path.join(base_dir, 'images/train')
train_labels_dir = os.path.join(base_dir, 'labels/train')

# Assuming image_paths is a list of paths to images in train_img_dir
image_paths = [os.path.join(train_img_dir, img) for img in os.listdir(train_img_dir) if img.endswith('.jpg')]

# Define the labels dataframe
root = os.path.join(base_dir, 'labels')
dfs = []
for subfolder in ['val', 'train']:
    for input_file in glob(pathname=os.path.join(root, subfolder, '*.txt')):
        current_df = pd.read_csv(filepath_or_buffer=input_file, sep=' ', names=['label', 'w0', 'w1', 'w2', 'w3'])
        current_df['tag'] = [subfolder] * len(current_df)
        current_df['name'] = basename(input_file)
        dfs.append(current_df)
labels_df = pd.concat(objs=dfs, axis=0)
labels_df['image_name'] = labels_df['name'].apply(lambda x: x.replace('.txt', '.jpg'))
labels_df['class'] = labels_df['label'].map({0: 'scratch', 1: 'dot', 2: 'crease', 3: 'damage'})

# Assume the `shap_values` array is already defined
# Example dummy `shap_values` array for illustration; replace with actual shap_values
shap_values = np.random.rand(len(image_paths), len(labels_df.columns))

# Visualize the top images with bounding boxes for w2 and w3
visualize_top_images_with_bboxes('w2', shap_values, image_paths, labels_df)
visualize_top_images_with_bboxes('w3', shap_values, image_paths, labels_df)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image
import os
from glob import glob

# Define the function to visualize images with bounding boxes
def visualize_top_images_with_bboxes(feature_name, shap_values, image_paths, labels_df, n=3):
    # Get the indices of the images with the highest SHAP values for the given feature
    shap_values_for_feature = shap_values[:, labels_df.columns.get_loc(feature_name)]
    top_indices = np.argsort(-np.abs(shap_values_for_feature))[:n]

    for idx in top_indices:
        image_path = image_paths[idx]
        shap_value = shap_values_for_feature[idx]

        # Read the image
        try:
            image = Image.open(image_path)
        except FileNotFoundError:
            print(f"File not found: {image_path}")
            continue

        # Get bounding box coordinates from labels_df
        image_name = os.path.basename(image_path)
        original_image_name = image_name.split('_')[0] + '.jpg'
        label_row = labels_df[labels_df['image_name'] == original_image_name]
        if not label_row.empty:
            w2, w3 = label_row[['w2', 'w3']].values[0]
            print(f"Bounding box for {image_name}: w2={w2}, w3={w3}")
        else:
            print(f"No label data found for image {image_path}")
            continue

        # Plot the image
        fig, ax = plt.subplots(1)
        ax.imshow(image)

        # Define the size and position of the bounding box
        img_width, img_height = image.size
        box_width = img_width * 0.1  # Set the box width to 10% of the image width
        box_height = img_height * 0.1  # Set the box height to 10% of the image height
        top_left_x = img_width * w2
        top_left_y = img_height * w3

        # Create a Rectangle patch
        rect = patches.Rectangle((top_left_x, top_left_y), box_width, box_height, linewidth=2, edgecolor='r', facecolor='none')

        # Add the patch to the Axes
        ax.add_patch(rect)

        plt.title(f'SHAP value for {feature_name}: {shap_value:.4f}')
        plt.show()

# Securely handle Kaggle API key
os.makedirs('/root/.kaggle', exist_ok=True)
with open('/root/.kaggle/kaggle.json', 'w') as f:
    f.write('{"username":"samimohammadi","key":"4ab63d79c9e2574c91adf402d3ed7aec"}')
os.chmod('/root/.kaggle/kaggle.json', 0o600)

# Download and unzip dataset
!kaggle datasets download -d wolfmedal/aero-engine-defect-new
with zipfile.ZipFile('aero-engine-defect-new.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/aero-engine-defect-new')

# Verify the correct paths
base_dir = '/content/aero-engine-defect-new/Aero-engine_defect-detect_new'
train_img_dir = os.path.join(base_dir, 'images/train')
train_labels_dir = os.path.join(base_dir, 'labels/train')

# Assuming image_paths is a list of paths to images in train_img_dir
image_paths = [os.path.join(train_img_dir, img) for img in os.listdir(train_img_dir) if img.endswith('.jpg')]

# Define the labels dataframe
root = os.path.join(base_dir, 'labels')
dfs = []
for subfolder in ['val', 'train']:
    for input_file in glob(pathname=os.path.join(root, subfolder, '*.txt')):
        current_df = pd.read_csv(filepath_or_buffer=input_file, sep=' ', names=['label', 'w0', 'w1', 'w2', 'w3'])
        current_df['tag'] = [subfolder] * len(current_df)
        current_df['name'] = os.path.basename(input_file)
        dfs.append(current_df)
labels_df = pd.concat(objs=dfs, axis=0)
labels_df['image_name'] = labels_df['name'].apply(lambda x: x.replace('.txt', '.jpg'))
labels_df['class'] = labels_df['label'].map({0: 'scratch', 1: 'dot', 2: 'crease', 3: 'damage'})

# Assume the `shap_values` array is already defined
# Example dummy `shap_values` array for illustration; replace with actual shap_values
shap_values = np.random.rand(len(image_paths), len(labels_df.columns))

# Visualize the top images with bounding boxes for w2 and w3
visualize_top_images_with_bboxes('w2', shap_values, image_paths, labels_df)
visualize_top_images_with_bboxes('w3', shap_values, image_paths, labels_df)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image
import os
from glob import glob

# Define the function to visualize images with bounding boxes based on combined top features
def visualize_combined_top_images_with_bboxes(shap_values, image_paths, labels_df, n=10):
    # Get the indices of the images with the highest combined SHAP values for the top n features
    top_features = shap_values[:, :n]
    combined_shap_values = np.sum(np.abs(top_features), axis=1)
    top_indices = np.argsort(-combined_shap_values)[:n]

    for idx in top_indices:
        image_path = image_paths[idx]
        combined_shap_value = combined_shap_values[idx]

        # Read the image
        try:
            image = Image.open(image_path)
        except FileNotFoundError:
            print(f"File not found: {image_path}")
            continue

        # Get bounding box coordinates from labels_df
        image_name = os.path.basename(image_path)
        original_image_name = image_name.split('_')[0] + '.jpg'
        label_row = labels_df[labels_df['image_name'] == original_image_name]
        if not label_row.empty:
            # Averaging the coordinates of the top features
            w_coords = label_row[['w' + str(i) for i in range(n)]].values[0]
            avg_w_coord = np.mean(w_coords)
            w2, w3 = avg_w_coord, avg_w_coord
            print(f"Bounding box for {image_name}: w2={w2}, w3={w3}")
        else:
            print(f"No label data found for image {image_path}")
            continue

        # Plot the image
        fig, ax = plt.subplots(1)
        ax.imshow(image)

        # Define the size and position of the bounding box
        img_width, img_height = image.size
        box_width = img_width * 0.1  # Set the box width to 10% of the image width
        box_height = img_height * 0.1  # Set the box height to 10% of the image height
        top_left_x = img_width * w2
        top_left_y = img_height * w3

        # Create a Rectangle patch
        rect = patches.Rectangle((top_left_x, top_left_y), box_width, box_height, linewidth=2, edgecolor='r', facecolor='none')

        # Add the patch to the Axes
        ax.add_patch(rect)

        plt.title(f'Combined SHAP value: {combined_shap_value:.4f}')
        plt.show()

# Securely handle Kaggle API key
os.makedirs('/root/.kaggle', exist_ok=True)
with open('/root/.kaggle/kaggle.json', 'w') as f:
    f.write('{"username":"samimohammadi","key":"4ab63d79c9e2574c91adf402d3ed7aec"}')
os.chmod('/root/.kaggle/kaggle.json', 0o600)

# Download and unzip dataset
!kaggle datasets download -d wolfmedal/aero-engine-defect-new
with zipfile.ZipFile('aero-engine-defect-new.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/aero-engine-defect-new')

# Verify the correct paths
base_dir = '/content/aero-engine-defect-new/Aero-engine_defect-detect_new'
train_img_dir = os.path.join(base_dir, 'images/train')
train_labels_dir = os.path.join(base_dir, 'labels/train')

# Assuming image_paths is a list of paths to images in train_img_dir
image_paths = [os.path.join(train_img_dir, img) for img in os.listdir(train_img_dir) if img.endswith('.jpg')]

# Define the labels dataframe
root = os.path.join(base_dir, 'labels')
dfs = []
for subfolder in ['val', 'train']:
    for input_file in glob(pathname=os.path.join(root, subfolder, '*.txt')):
        current_df = pd.read_csv(filepath_or_buffer=input_file, sep=' ', names=['label', 'w0', 'w1', 'w2', 'w3', 'w4', 'w5', 'w6', 'w7', 'w8', 'w9'])
        current_df['tag'] = [subfolder] * len(current_df)
        current_df['name'] = os.path.basename(input_file)
        dfs.append(current_df)
labels_df = pd.concat(objs=dfs, axis=0)
labels_df['image_name'] = labels_df['name'].apply(lambda x: x.replace('.txt', '.jpg'))
labels_df['class'] = labels_df['label'].map({0: 'scratch', 1: 'dot', 2: 'crease', 3: 'damage'})

# Assume the `shap_values` array is already defined
# Example dummy `shap_values` array for illustration; replace with actual shap_values
shap_values = np.random.rand(len(image_paths), len(labels_df.columns))

# Visualize the top images with bounding boxes for the combined top 10 features
visualize_combined_top_images_with_bboxes(shap_values, image_paths, labels_df)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image
import os
from glob import glob

# Define the function to visualize images with bounding boxes based on combined top features
def visualize_combined_top_images_with_bboxes(shap_values, image_paths, labels_df, n=10):
    # Get the indices of the images with the highest combined SHAP values for the top n features
    top_features = shap_values[:, :n]
    combined_shap_values = np.sum(np.abs(top_features), axis=1)
    top_indices = np.argsort(-combined_shap_values)[:n]

    for idx in top_indices:
        image_path = image_paths[idx]
        combined_shap_value = combined_shap_values[idx]

        # Read the image
        try:
            image = Image.open(image_path)
        except FileNotFoundError:
            print(f"File not found: {image_path}")
            continue

        # Get bounding box coordinates from labels_df
        image_name = os.path.basename(image_path)
        original_image_name = image_name.split('_')[0] + '.jpg'
        label_row = labels_df[labels_df['image_name'] == original_image_name]
        if not label_row.empty:
            # Averaging the coordinates of the top features
            w_coords = label_row[['w' + str(i) for i in range(n)]].values[0]
            avg_w_coord = np.mean(w_coords)
            w2, w3 = avg_w_coord, avg_w_coord
            print(f"Bounding box for {image_name}: w2={w2}, w3={w3}")
        else:
            print(f"No label data found for image {image_path}")
            continue

        # Plot the image
        fig, ax = plt.subplots(1)
        ax.imshow(image)

        # Define the size and position of the bounding box
        img_width, img_height = image.size
        box_width = img_width * 0.1  # Set the box width to 10% of the image width
        box_height = img_height * 0.1  # Set the box height to 10% of the image height
        top_left_x = img_width * w2
        top_left_y = img_height * w3

        # Create a Rectangle patch
        rect = patches.Rectangle((top_left_x, top_left_y), box_width, box_height, linewidth=2, edgecolor='r', facecolor='none')

        # Add the patch to the Axes
        ax.add_patch(rect)

        plt.title(f'Combined SHAP value: {combined_shap_value:.4f}')
        plt.show()

# Securely handle Kaggle API key
os.makedirs('/root/.kaggle', exist_ok=True)
with open('/root/.kaggle/kaggle.json', 'w') as f:
    f.write('{"username":"samimohammadi","key":"4ab63d79c9e2574c91adf402d3ed7aec"}')
os.chmod('/root/.kaggle/kaggle.json', 0o600)

# Download and unzip dataset
!kaggle datasets download -d wolfmedal/aero-engine-defect-new
with zipfile.ZipFile('aero-engine-defect-new.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/aero-engine-defect-new')

# Verify the correct paths
base_dir = '/content/aero-engine-defect-new/Aero-engine_defect-detect_new'
train_img_dir = os.path.join(base_dir, 'images/train')
train_labels_dir = os.path.join(base_dir, 'labels/train')

# Assuming image_paths is a list of paths to images in train_img_dir
image_paths = [os.path.join(train_img_dir, img) for img in os.listdir(train_img_dir) if img.endswith('.jpg')]

# Define the labels dataframe
root = os.path.join(base_dir, 'labels')
dfs = []
for subfolder in ['val', 'train']:
    for input_file in glob(pathname=os.path.join(root, subfolder, '*.txt')):
        current_df = pd.read_csv(filepath_or_buffer=input_file, sep=' ', names=['label', 'w0', 'w1', 'w2', 'w3', 'w4', 'w5', 'w6', 'w7', 'w8', 'w9'])
        current_df['tag'] = [subfolder] * len(current_df)
        current_df['name'] = os.path.basename(input_file)
        dfs.append(current_df)
labels_df = pd.concat(objs=dfs, axis=0)
labels_df['image_name'] = labels_df['name'].apply(lambda x: x.replace('.txt', '.jpg'))
labels_df['class'] = labels_df['label'].map({0: 'scratch', 1: 'dot', 2: 'crease', 3: 'damage'})

# Assume the `shap_values` array is already defined
# Example dummy `shap_values` array for illustration; replace with actual shap_values
shap_values = np.random.rand(len(image_paths), len(labels_df.columns))

# Visualize the top images with bounding boxes for the combined top 10 features
visualize_combined_top_images_with_bboxes(shap_values, image_paths, labels_df)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image
import os
from glob import glob

# Define the function to visualize images with bounding boxes based on combined top features
def visualize_combined_top_images_with_bboxes(shap_values, image_paths, labels_df, top_n=10):
    # Get the indices of the images with the highest combined SHAP values for the top n features
    combined_shap_values = np.sum(np.abs(shap_values[:, :top_n]), axis=1)
    top_indices = np.argsort(-combined_shap_values)[:top_n]

    for idx in top_indices:
        image_path = image_paths[idx]
        combined_shap_value = combined_shap_values[idx]

        # Read the image
        try:
            image = Image.open(image_path)
        except FileNotFoundError:
            print(f"File not found: {image_path}")
            continue

        # Get bounding box coordinates from labels_df
        image_name = os.path.basename(image_path)
        original_image_name = image_name.split('_')[0] + '.jpg'
        label_row = labels_df[labels_df['image_name'] == original_image_name]
        if not label_row.empty:
            # Averaging the coordinates of the top features
            w_coords = label_row[['w0', 'w1', 'w2', 'w3', 'w4', 'w5', 'w6', 'w7', 'w8', 'w9']].values[0]
            print(f"Bounding box for {image_name}: {w_coords}")
        else:
            print(f"No label data found for image {image_path}")
            continue

        # Plot the image
        fig, ax = plt.subplots(1)
        ax.imshow(image)

        # Define the size and position of the bounding box
        img_width, img_height = image.size

        # Draw bounding boxes for each feature coordinate
        for coord in w_coords:
            box_width = img_width * 0.1  # Set the box width to 10% of the image width
            box_height = img_height * 0.1  # Set the box height to 10% of the image height
            top_left_x = img_width * coord
            top_left_y = img_height * coord

            # Create a Rectangle patch
            rect = patches.Rectangle((top_left_x, top_left_y), box_width, box_height, linewidth=2, edgecolor='r', facecolor='none')

            # Add the patch to the Axes
            ax.add_patch(rect)

        plt.title(f'Combined SHAP value: {combined_shap_value:.4f}')
        plt.show()

# Securely handle Kaggle API key
os.makedirs('/root/.kaggle', exist_ok=True)
with open('/root/.kaggle/kaggle.json', 'w') as f:
    f.write('{"username":"samimohammadi","key":"4ab63d79c9e2574c91adf402d3ed7aec"}')
os.chmod('/root/.kaggle/kaggle.json', 0o600)

# Download and unzip dataset
!kaggle datasets download -d wolfmedal/aero-engine-defect-new
with zipfile.ZipFile('aero-engine-defect-new.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/aero-engine-defect-new')

# Verify the correct paths
base_dir = '/content/aero-engine-defect-new/Aero-engine_defect-detect_new'
train_img_dir = os.path.join(base_dir, 'images/train')
train_labels_dir = os.path.join(base_dir, 'labels/train')

# Assuming image_paths is a list of paths to images in train_img_dir
image_paths = [os.path.join(train_img_dir, img) for img in os.listdir(train_img_dir) if img.endswith('.jpg')]

# Define the labels dataframe
root = os.path.join(base_dir, 'labels')
dfs = []
for subfolder in ['val', 'train']:
    for input_file in glob(pathname=os.path.join(root, subfolder, '*.txt')):
        current_df = pd.read_csv(filepath_or_buffer=input_file, sep=' ', names=['label', 'w0', 'w1', 'w2', 'w3', 'w4', 'w5', 'w6', 'w7', 'w8', 'w9'])
        current_df['tag'] = [subfolder] * len(current_df)
        current_df['name'] = os.path.basename(input_file)
        dfs.append(current_df)
labels_df = pd.concat(objs=dfs, axis=0)
labels_df['image_name'] = labels_df['name'].apply(lambda x: x.replace('.txt', '.jpg'))
labels_df['class'] = labels_df['label'].map({0: 'scratch', 1: 'dot', 2: 'crease', 3: 'damage'})

# Assume the `shap_values` array is already defined
# Example dummy `shap_values` array for illustration; replace with actual shap_values
shap_values = np.random.rand(len(image_paths), len(labels_df.columns))

# Visualize the top images with bounding boxes for the combined top 10 features
visualize_combined_top_images_with_bboxes(shap_values, image_paths, labels_df)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image
import os
from glob import glob

# Define the function to visualize images with bounding boxes based on specific top features
def visualize_specific_top_images_with_bboxes(shap_values, image_paths, labels_df, top_features):
    # Get the indices of the images with the highest combined SHAP values for the specified top features
    top_indices = np.argsort(-np.sum(np.abs(shap_values[:, top_features]), axis=1))[:len(top_features)]

    for idx in top_indices:
        image_path = image_paths[idx]
        combined_shap_value = np.sum(np.abs(shap_values[idx, top_features]))

        # Read the image
        try:
            image = Image.open(image_path)
        except FileNotFoundError:
            print(f"File not found: {image_path}")
            continue

        # Get bounding box coordinates from labels_df
        image_name = os.path.basename(image_path)
        original_image_name = image_name.split('_')[0] + '.jpg'
        label_row = labels_df[labels_df['image_name'] == original_image_name]
        if not label_row.empty:
            # Extract coordinates for top features
            coords = label_row[['w0', 'w1', 'w2', 'w3']].values[0]
            print(f"Bounding box for {image_name}: {coords}")
        else:
            print(f"No label data found for image {image_path}")
            continue

        # Plot the image
        fig, ax = plt.subplots(1)
        ax.imshow(image)

        # Define the size and position of the bounding boxes for the specified features
        img_width, img_height = image.size

        # Draw bounding boxes for each feature coordinate
        for coord in coords:
            box_width = img_width * 0.1  # Set the box width to 10% of the image width
            box_height = img_height * 0.1  # Set the box height to 10% of the image height
            top_left_x = img_width * coord
            top_left_y = img_height * coord

            # Create a Rectangle patch
            rect = patches.Rectangle((top_left_x, top_left_y), box_width, box_height, linewidth=2, edgecolor='r', facecolor='none')

            # Add the patch to the Axes
            ax.add_patch(rect)

        plt.title(f'Combined SHAP value: {combined_shap_value:.4f}')
        plt.show()

# Securely handle Kaggle API key
os.makedirs('/root/.kaggle', exist_ok=True)
with open('/root/.kaggle/kaggle.json', 'w') as f:
    f.write('{"username":"samimohammadi","key":"4ab63d79c9e2574c91adf402d3ed7aec"}')
os.chmod('/root/.kaggle/kaggle.json', 0o600)

# Download and unzip dataset
!kaggle datasets download -d wolfmedal/aero-engine-defect-new
with zipfile.ZipFile('aero-engine-defect-new.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/aero-engine-defect-new')

# Verify the correct paths
base_dir = '/content/aero-engine-defect-new/Aero-engine_defect-detect_new'
train_img_dir = os.path.join(base_dir, 'images/train')
train_labels_dir = os.path.join(base_dir, 'labels/train')

# Assuming image_paths is a list of paths to images in train_img_dir
image_paths = [os.path.join(train_img_dir, img) for img in os.listdir(train_img_dir) if img.endswith('.jpg')]

# Define the labels dataframe
root = os.path.join(base_dir, 'labels')
dfs = []
for subfolder in ['val', 'train']:
    for input_file in glob(pathname=os.path.join(root, subfolder, '*.txt')):
        current_df = pd.read_csv(filepath_or_buffer=input_file, sep=' ', names=['label', 'w0', 'w1', 'w2', 'w3', 'w4', 'w5', 'w6', 'w7', 'w8', 'w9'])
        current_df['tag'] = [subfolder] * len(current_df)
        current_df['name'] = os.path.basename(input_file)
        dfs.append(current_df)
labels_df = pd.concat(objs=dfs, axis=0)
labels_df['image_name'] = labels_df['name'].apply(lambda x: x.replace('.txt', '.jpg'))
labels_df['class'] = labels_df['label'].map({0: 'scratch', 1: 'dot', 2: 'crease', 3: 'damage'})

# Assume the `shap_values` array is already defined
# Example dummy `shap_values` array for illustration; replace with actual shap_values
shap_values = np.random.rand(len(image_paths), len(labels_df.columns))

# Define the top features based on SHAP summary plot
top_features = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  # Assuming these indices correspond to 'w2', 'w3', '679', '269', '731', '102', 'w0', '29', '87', and '611'

# Visualize the top images with bounding boxes for the specified top features
visualize_specific_top_images_with_bboxes(shap_values, image_paths, labels_df, top_features)

import matplotlib.pyplot as plt
from PIL import Image, ImageDraw
import numpy as np

# Function to visualize the top images with bounding boxes for a given dimension index
def visualize_top_activations_with_bounding_boxes(dimension_index, embeddings, image_paths, top_n=5):
    # Ensure embeddings and image_paths are numpy arrays
    embeddings = np.array(embeddings)
    image_paths = np.array(image_paths)

    # Extract values for the given dimension
    dimension_values = embeddings[:, dimension_index]

    # Get indices of top N values
    top_indices = np.argsort(dimension_values)[-top_n:]

    # Get corresponding images and values
    top_images = [image_paths[i] for i in top_indices]
    top_values = dimension_values[top_indices]

    # Plot images with their values and draw bounding boxes
    fig, axes = plt.subplots(1, top_n, figsize=(15, 5))
    for ax, img_path, val in zip(axes, top_images, top_values):
        img = Image.open(img_path)
        draw = ImageDraw.Draw(img)

        # Approximate bounding box coordinates (centered in the image)
        img_width, img_height = img.size
        box_size = min(img_width, img_height) // 4
        left = (img_width - box_size) // 2
        top = (img_height - box_size) // 2
        right = left + box_size
        bottom = top + box_size
        draw.rectangle([left, top, right, bottom], outline="red", width=3)

        ax.imshow(img)
        ax.set_title(f'Value: {val:.2f}')
        ax.axis('off')
    plt.suptitle(f'Top {top_n} images for embedding dimension {dimension_index}')
    plt.show()

# List of the top 10 dimensions based on their real indices from the SHAP summary plot
top_10_dimensions = [2, 3, 679, 269, 731, 102, 0, 29, 87, 611]

# Visualize the top images with bounding boxes for each of the top 10 dimensions
for dim in top_10_dimensions:
    visualize_top_activations_with_bounding_boxes(dim, np.array(embeddings), image_paths, top_n=5)